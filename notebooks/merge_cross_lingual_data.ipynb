{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "def load_json(file_path):\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_corpus_vi = {}\n",
    "merged_corpus_en = {}\n",
    "merged_queries_vi = {}\n",
    "merged_queries_en = {}\n",
    "merged_train_data_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVPL SFT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries_vi = load_json(\"../data/eval/law/train_queries.json\")\n",
    "train_queries_en = load_json(\"../data/eval/law/train_queries_en.json\")\n",
    "filtered_corpus_vi = load_json(\"../data/eval/law/filtered_corpus.json\")\n",
    "filtered_corpus_en = load_json(\"../data/eval/law/filtered_corpus_en.json\")\n",
    "reindexed_corpus_en = load_json(\"../data/eval/law/reindexed_corpus_en.json\")\n",
    "reindexed_corpus_vi = load_json(\"../data/eval/law/reindexed_corpus.json\")\n",
    "reindexed_corpus_vi = {f\"oid_{k}\": reindexed_corpus_vi[k] for k in reindexed_corpus_en.keys()}\n",
    "reindexed_corpus_en = {f\"oid_{k}\": v for k, v in reindexed_corpus_en.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in train_queries_vi.items():\n",
    "    merged_queries_vi[f\"tvpl_{k}\"] = v\n",
    "for k, v in train_queries_en.items():\n",
    "    merged_queries_en[f\"tvpl_{k}\"] = v\n",
    "for k, v in filtered_corpus_vi.items():\n",
    "    merged_corpus_vi[f\"tvpl_{k}\"] = v\n",
    "for k, v in filtered_corpus_en.items():\n",
    "    merged_corpus_en[f\"tvpl_{k}\"] = v\n",
    "for k, v in reindexed_corpus_vi.items():\n",
    "    merged_corpus_vi[f\"tvpl_{k}\"] = v\n",
    "for k, v in reindexed_corpus_en.items():\n",
    "    merged_corpus_en[f\"tvpl_{k}\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165347it [00:01, 115009.50it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/sft/train_data_minedHN_v3_ids.jsonl\") as fIn:\n",
    "    for line in tqdm(fIn):\n",
    "        item = json.loads(line)\n",
    "        new_item = {}\n",
    "        new_item[\"query\"] = f\"tvpl_{item['query']}\"\n",
    "        new_item[\"pos\"] = [f\"tvpl_{x}\" for x in item[\"pos\"]]\n",
    "        new_item[\"neg\"] = [f\"tvpl_{x}\" for x in item[\"neg\"]]\n",
    "        merged_train_data_ids.append(new_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zalo Legal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries_vi = load_json(\"../data/eval/zalo_legal/train_queries.json\")\n",
    "train_queries_en = load_json(\"../data/eval/zalo_legal/train_queries_en.json\")\n",
    "filtered_corpus_vi = load_json(\"../data/eval/zalo_legal/filtered_corpus.json\")\n",
    "filtered_corpus_en =  load_json(\"../data/eval/zalo_legal/filtered_corpus_en.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in train_queries_vi.items():\n",
    "    merged_queries_vi[f\"zalolegal_{k}\"] = v\n",
    "for k, v in train_queries_en.items():\n",
    "    merged_queries_en[f\"zalolegal_{k}\"] = v\n",
    "for k, v in filtered_corpus_vi.items():\n",
    "    merged_corpus_vi[f\"zalolegal_{k}\"] = v\n",
    "for k, v in filtered_corpus_en.items():\n",
    "    merged_corpus_en[f\"zalolegal_{k}\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2556it [00:00, 171231.63it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/sft/zalolegal_train_data_minedHN_ids.jsonl\") as fIn:\n",
    "    for line in tqdm(fIn):\n",
    "        item = json.loads(line)\n",
    "        new_item = {}\n",
    "        new_item[\"query\"] = f\"zalolegal_{item['query']}\"\n",
    "        new_item[\"pos\"] = [f\"zalolegal_{x}\" for x in item[\"pos\"]]\n",
    "        new_item[\"neg\"] = [f\"zalolegal_{x}\" for x in item[\"neg\"]]\n",
    "        merged_train_data_ids.append(new_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSMARCO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries_vi = load_json(\"../data/eval/msmarco/queries.json\")\n",
    "all_queries_en = load_json(\"../data/eval/msmarco/queries_en.json\")\n",
    "filtered_corpus_vi = load_json(\"../data/eval/msmarco/collections.json\")\n",
    "filtered_corpus_en = load_json(\"../data/eval/msmarco/collections_en.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "457361it [00:01, 242616.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# only keep the used query\n",
    "train_queries_vi = {}\n",
    "train_queries_en = {}\n",
    "\n",
    "with open(\"../data/sft/msmarco_train_data_minedHN_ids.jsonl\") as fIn:\n",
    "    for line in tqdm(fIn):\n",
    "        item = json.loads(line)\n",
    "        train_queries_vi[item[\"query\"]] = all_queries_vi[item[\"query\"]]\n",
    "        train_queries_en[item[\"query\"]] = all_queries_en[item[\"query\"]]\n",
    "        \n",
    "with open(\"../data/eval/msmarco/train_queries.json\", \"w\") as fOut:\n",
    "    json.dump(train_queries_vi, fOut, ensure_ascii=False, indent=2)\n",
    "with open(\"../data/eval/msmarco/train_queries_en.json\", \"w\") as fOut:\n",
    "    json.dump(train_queries_en, fOut, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in train_queries_vi.items():\n",
    "    merged_queries_vi[f\"msmarco_{k}\"] = v\n",
    "for k, v in train_queries_en.items():\n",
    "    merged_queries_en[f\"msmarco_{k}\"] = v\n",
    "for k, v in filtered_corpus_vi.items():\n",
    "    merged_corpus_vi[f\"msmarco_{k}\"] = v\n",
    "for k, v in filtered_corpus_en.items():\n",
    "    merged_corpus_en[f\"msmarco_{k}\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "457361it [00:04, 106367.63it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/sft/msmarco_train_data_minedHN_ids.jsonl\") as fIn:\n",
    "    for line in tqdm(fIn):\n",
    "        item = json.loads(line)\n",
    "        new_item = {}\n",
    "        new_item[\"query\"] = f\"msmarco_{item['query']}\"\n",
    "        new_item[\"pos\"] = [f\"msmarco_{x}\" for x in item[\"pos\"]]\n",
    "        new_item[\"neg\"] = [f\"msmarco_{x}\" for x in item[\"neg\"]]\n",
    "        merged_train_data_ids.append(new_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuADv2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries_vi = load_json(\"../data/eval/squadv2/queries.json\")\n",
    "train_queries_en = load_json(\"../data/eval/squadv2/queries_en.json\")\n",
    "filtered_corpus_vi = load_json(\"../data/eval/squadv2/collections.json\")\n",
    "filtered_corpus_en = load_json(\"../data/eval/squadv2/collections_en.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in train_queries_vi.items():\n",
    "    merged_queries_vi[f\"squadv2_{k}\"] = v\n",
    "for k, v in train_queries_en.items():\n",
    "    merged_queries_en[f\"squadv2_{k}\"] = v\n",
    "for k, v in filtered_corpus_vi.items():\n",
    "    merged_corpus_vi[f\"squadv2_{k}\"] = v\n",
    "for k, v in filtered_corpus_en.items():\n",
    "    merged_corpus_en[f\"squadv2_{k}\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60942it [00:00, 284031.13it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/sft/squadv2_train_data_minedHN_ids.jsonl\") as fIn:\n",
    "    for line in tqdm(fIn):\n",
    "        item = json.loads(line)\n",
    "        new_item = {}\n",
    "        new_item[\"query\"] = f\"squadv2_{item['query']}\"\n",
    "        new_item[\"pos\"] = [f\"squadv2_{x}\" for x in item[\"pos\"]]\n",
    "        new_item[\"neg\"] = [f\"squadv2_{x}\" for x in item[\"neg\"]]\n",
    "        merged_train_data_ids.append(new_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(686206, 686206)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_queries_vi), len(merged_queries_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "686206"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_train_data_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3732381, 3732381)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_corpus_vi), len(merged_corpus_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'squadv2_24736',\n",
       " 'pos': ['squadv2_5661'],\n",
       " 'neg': ['squadv2_7561',\n",
       "  'squadv2_9608',\n",
       "  'squadv2_8941',\n",
       "  'squadv2_4790',\n",
       "  'squadv2_8925']}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train_data_ids[650000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Người Do Thái ở Đức tìm cách cải cách tín ngưỡng của người Do Thái khi nào?',\n",
       " 'When did the German Jewry seek to reform Jewish belief?')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_queries_vi[\"squadv2_24736\"], merged_queries_en[\"squadv2_24736\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Nguồn gốc của Do Thái giáo Chính thống có thể bắt nguồn từ cuối thế kỷ 18 hoặc đầu thế kỷ 19, khi các thành phần trong người Do Thái ở Đức tìm cách cải cách tín ngưỡng và thực hành của người Do Thái vào đầu thế kỷ 19 để đáp lại Thời đại Khai sáng, Giải phóng Do Thái và Haskalah. Họ tìm cách hiện đại hóa nền giáo dục dựa trên nền tảng học thuật đương thời. Họ bác bỏ những tuyên bố về quyền tác giả thiêng liêng tuyệt đối của Kinh Torah, tuyên bố chỉ có các luật trong Kinh thánh liên quan đến đạo đức là có tính ràng buộc và tuyên bố rằng phần còn lại của halakha (luật Do Thái) không cần phải được coi là quy chuẩn đối với người Do Thái trong xã hội rộng lớn hơn. (xem Cải cách Do Thái giáo).',\n",
       " 'The roots of Orthodox Judaism can be traced to the late 18th or early 19th century, when elements within German Jewry sought to reform Jewish belief and practice in the early 19th century in response to the Age of Enlightenment, Jewish Emancipation, and Haskalah. They sought to modernize education in light of contemporary scholarship. They rejected claims of the absolute divine authorship of the Torah, declaring only biblical laws concerning ethics to be binding, and stated that the rest of halakha (Jewish law) need not be viewed as normative for Jews in wider society. (see Reform Judaism).')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_corpus_vi[\"squadv2_5661\"], merged_corpus_en[\"squadv2_5661\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 686206/686206 [00:08<00:00, 76745.43it/s] \n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(merged_train_data_ids):\n",
    "    assert item[\"query\"] in merged_queries_vi\n",
    "    assert item[\"query\"] in merged_queries_en\n",
    "    \n",
    "    assert all(x in merged_corpus_vi for x in item[\"pos\"])\n",
    "    assert all(x in merged_corpus_en for x in item[\"pos\"])\n",
    "    \n",
    "    assert all(x in merged_corpus_vi for x in item[\"neg\"])\n",
    "    assert all(x in merged_corpus_en for x in item[\"neg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/cross_lingual/merged_queries_vi.json\", \"w\", encoding='utf-8') as fOut:\n",
    "    json.dump(merged_queries_vi, fOut, ensure_ascii=False, indent=2)\n",
    "with open(\"../data/cross_lingual/merged_queries_en.json\", \"w\", encoding='utf-8') as fOut:\n",
    "    json.dump(merged_queries_en, fOut, ensure_ascii=False, indent=2)\n",
    "    \n",
    "with open(\"../data/cross_lingual/merged_corpus_vi.json\", \"w\", encoding='utf-8') as fOut:\n",
    "    json.dump(merged_corpus_vi, fOut, ensure_ascii=False, indent=2)\n",
    "with open(\"../data/cross_lingual/merged_corpus_en.json\", \"w\", encoding='utf-8') as fOut:\n",
    "    json.dump(merged_corpus_en, fOut, ensure_ascii=False, indent=2)\n",
    "    \n",
    "with open(\"../data/cross_lingual/merged_train_data_ids.jsonl\", \"w\") as fOut:\n",
    "    for item in merged_train_data_ids:\n",
    "        fOut.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toannn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
